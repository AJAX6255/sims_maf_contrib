{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Delay Accuracy and Precision\n",
    "\n",
    "_Phil Marshall & Lynne Jones_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first [Time Delay Challenge](http://timedelaychallenge.org) paper, [Liao et al (2015)](http://arxiv.org/pdf/1409.1254.pdf) derived the following simple model for how strongly gravitationally lensed quasar time delay accuracy (A), precision (P) and success rate (f) depend on the night-to-night cadence, season and campaign length. \n",
    "wrote several metrics and stackers to determine time delay accuracy (A), precision (P) and success rate (f). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "|A|_{\\rm model} &\\approx 0.06\\% \\left(\\frac{\\rm cad} {\\rm 3 days}  \\right)^{0.0}\n",
    "                          \\left(\\frac{\\rm sea}  {\\rm 4 months}\\right)^{-1.0}\n",
    "                          \\left(\\frac{\\rm camp}{\\rm 5 years} \\right)^{-1.1} \\notag \\\\\n",
    "  P_{\\rm model} &\\approx 4.0\\% \\left(\\frac{\\rm cad} {\\rm 3 days}  \\right)^{ 0.7}\n",
    "                         \\left(\\frac{\\rm sea}  {\\rm 4 months}\\right)^{-0.3}\n",
    "                         \\left(\\frac{\\rm camp}{\\rm 5 years} \\right)^{-0.6} \\notag \\\\\n",
    "  f_{\\rm model} &\\approx 30\\% \\left(\\frac{\\rm cad} {\\rm 3 days}  \\right)^{-0.4}\n",
    "                        \\left(\\frac{\\rm sea}  {\\rm 4 months}\\right)^{ 0.8}\n",
    "                        \\left(\\frac{\\rm camp}{\\rm 5 years} \\right)^{-0.2} \\notag\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two of these metrics are candidate Figure of Merit proxies, while one can imagine combining all three somehow to provide an approximate dark energy parameter Figuer of Merit. These three metrics are implemented in [`tdcMetric.py`](http://github.com/LSST-nonproject/sims_maf_contrib/tree/master/mafContrib/tdcMetric.py) of the  [sims_maf_contrib](http://github.com/LSST-nonproject/sims_maf_contrib) git repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a demo calculation of these metrics, using the MAF python interface (requires sims_maf version >= 1.0). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "You'll need the `sims_maf_contrib` folder on your `PYTHONPATH`. For me, that meant doing:\n",
    "```bash\n",
    "export PYTHONPATH=$PYTHONPATH:/Users/pjm/work/stronglensing/LSST/ObservingStrategy/MAF/sims_maf_contrib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Import MAF modules.\n",
    "import lsst.sims.maf.db as db\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.stackers as stackers\n",
    "import lsst.sims.maf.plots as plots\n",
    "from lsst.sims.maf.metricBundles import MetricBundle, MetricBundleGroup\n",
    "# Import the contributed metrics and stackers \n",
    "import mafContrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up  the MAF Evaluation of the Baseline Cadence \n",
    "\n",
    "As usual, we need to set up a `MetricBundleGroup` object so that we can run all of the metrics it contains on a single `OpSim` output database, which we first have to connect to. The easiest way I found to do this is to link my copy of the database to the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runName = 'minion_1016'\n",
    "database = runName + '_sqlite.db'\n",
    "opsdb = db.OpsimDatabase(database)\n",
    "outDir = 'tmp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the metrics, stackers and slicer that we want to use. These are the TDC metrics, the season stacker, and the healpix slicer. Actually, since we'll just use the stackers in their default configuration, we don't need to explicitly instantiate the stackers -- MAF will handle that for us.  \n",
    "Note that our metric (`TdcMetric`) is actually a \"complex\" metric, as it calculates A, P, and f in one go (thus re-using the cadence/season/campaign values which must also be calculated for each set of visits), and then has 'reduce' methods that separate each of these individual results into separate values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric = mafContrib.TdcMetric(metricName='TDC', seasonCol='season', expMJDCol='expMJD', nightCol='night')\n",
    "slicer = slicers.HealpixSlicer(nside=64, lonCol='ditheredRA', latCol='ditheredDec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the plotFuncs so that we only create the skymap and histogram for each metric result. This is an optional step - otherwise, we'd just make the angular power spectra plots too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotFuncs = [plots.HealpixSkyMap, plots.HealpixHistogram]\n",
    "slicer.plotFuncs = plotFuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last ingredient we need is an SQL query to define the subset of visits we are interested in. Let's do something quick, like just the _i_ band in the first three years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlconstraint = 'night < %i and filter = \"i\"' % (3*365.25)\n",
    "tdcBundle = MetricBundle(metric=metric, slicer=slicer, sqlconstraint=sqlconstraint, runName=runName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultsDb = db.ResultsDb(outDir=outDir)\n",
    "bdict = {'tdc':tdcBundle}\n",
    "bgroup = MetricBundleGroup(bdict, opsdb, outDir=outDir, resultsDb=resultsDb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Metrics and Working with the Results\n",
    "\n",
    "We can query the database, run the stackers, run the metric calculation, and run the reduce functions with `runAll`. This would also generate summary statistics if we had defined any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgroup.runAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we now have more bundles in our bundle dictionary. These new bundles contain the results of the reduce functions - so, the metrics A, P, f separately as well as the \"cadence\", \"season\" and \"campaign\" diagnostics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bdict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to set the `plotDict` for each of these separately, so that we can get each plot to look \"just right\", and then we'll make the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minVal = 0.01\n",
    "maxVal = {'Accuracy':0.20, 'Precision':10.0, 'Rate':40, 'Cadence':14, 'Season':8.0, 'Campaign':11.0}\n",
    "units = {'Accuracy':'%', 'Precision':'%', 'Rate':'%', 'Cadence':'days', 'Season':'months', 'Campaign':'years'}\n",
    "for key in maxVal:\n",
    "    plotDict = {'xMin':minVal, 'xMax':maxVal[key], 'colorMin':minVal, 'colorMax':maxVal[key]}\n",
    "    plotDict['xlabel'] = 'TDC %s (%s)' % (key, units[key])\n",
    "    bdict['TDC_%s' % (key)].setPlotDict(plotDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgroup.plotAll(closefigs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tdcBundle.metricValues` array contains the `HEALPix` maps of each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdcBundle.metricValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some post-processing to turn the metric maps into single numbers for a table in the observing strategy white paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = tdcBundle.metricValues\n",
    "index = np.where(x.mask == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = np.array([each['rate'] for each in x[index]])\n",
    "A = np.array([each['accuracy'] for each in x[index]])\n",
    "P = np.array([each['precision'] for each in x[index]])\n",
    "c = np.array([each['cadence'] for each in x[index]])\n",
    "s = np.array([each['season'] for each in x[index]])\n",
    "y = np.array([each['campaign'] for each in x[index]])\n",
    "print np.mean(f), np.mean(A), np.mean(P), np.mean(c), np.mean(s), np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in lenses with high accuracy delays, i.e. the fraction of the survey area where the _A_ metric is below some threshold. We can turn this into a sky area if we know the average size of a `HEALPix` pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_threshold = 0.04 # 5 times better than threshold of 0.2% set by Hojjati & Linder (2014).\n",
    "\n",
    "high_accuracy = np.where(A < accuracy_threshold)\n",
    "high_fraction = 100*(1.0*len(A[high_accuracy]))/(1.0*len(A))\n",
    "print \"Fraction of total survey area providing high accuracy time delays = \",np.round(high_fraction,1),'%'\n",
    "\n",
    "high_accuracy_cadence = np.median(c[high_accuracy])\n",
    "print \"Median night-to-night cadence in high accuracy regions = \",np.round(high_accuracy_cadence,1),'days'\n",
    "\n",
    "high_accuracy_season = np.median(s[high_accuracy])\n",
    "print \"Median season length in high accuracy regions = \",np.round(high_accuracy_season,1),'months'\n",
    "\n",
    "high_accuracy_campaign = np.median(y[high_accuracy])\n",
    "print \"Median campaign length in high accuracy regions = \",int(high_accuracy_campaign),'years'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nside = 64\n",
    "Npix = 12*Nside**2\n",
    "Area_per_pixel = 4*np.pi / float(Npix) # steradians\n",
    "Area_per_pixel *= (180.0/np.pi)*(180.0/np.pi) # square degrees\n",
    "high_accuracy_area = len(A[high_accuracy])*Area_per_pixel\n",
    "print \"Area of sky providing high accuracy time delays = \",int(high_accuracy_area),\"sq deg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision_per_lens = np.array([np.mean(P[high_accuracy]),4.0])\n",
    "precision_per_lens = np.sqrt(np.sum(precision_per_lens*precision_per_lens))\n",
    "print \"Mean precision per lens in high accuracy sample, including modeling error = \",np.round(precision_per_lens,2),'%'\n",
    "\n",
    "fraction = np.mean(f[high_accuracy])\n",
    "N_lenses = int((high_accuracy_area/18000.0) * (fraction/30.0) * 400)\n",
    "print \"Number of lenses in high accuracy sample = \",N_lenses\n",
    "\n",
    "distance_precision = (precision_per_lens * (N_lenses > 0)) / (np.sqrt(N_lenses) + (N_lenses == 0))\n",
    "print \"Maximum combined percentage distance precision (as in Coe & Moustakas 2009) = \",np.round(distance_precision,2),'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above overall precision can be related to the cosmological parameter precision, and so is a reasonable proxy Figure of Merit. This quantity is plotted by [Treu & Marshall (2016)](http://arxiv.org/abs/1605.05333) in their recent review: their target for the LSST era is between 0.4 and 0.7%.\n",
    "\n",
    "The above analysis can all be repeated for alternative `OpSim` runs and SQL constraints, as we now show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Multiple `OpSim` Outputs\n",
    "\n",
    "Since we want to compare several runs, and draw conclusions about which observing strategy is best, let's make a function that does all this for us, given a specified `OpSim` run name and an SQL query to select just the filters we want (either all, or just _r_ and _i_). This is just all the code we just wrote, but packed into a `def`.\n",
    "\n",
    "### Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_opsim_run_for_time_delay_performance(runName='minion_1016', filters='ugrizy', Nyears=10):\n",
    "    '''\n",
    "    Sets up and executes a MAF analysis based on the Time Delay Challenge metrics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    runName : string ('minion_2016')\n",
    "        The name of an OpSim simulation, whose output database will be used.\n",
    "    filters : string ('ugrizy')\n",
    "        List of bands to be used in analysis.\n",
    "    Nyears : int\n",
    "        No. of years in campaign to be used in analysis, starting from night 0.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        Various summary statistics\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    '''\n",
    "    # Set up some of the metadata, and connect to the OpSim database. \n",
    "    database = runName + '_sqlite.db'\n",
    "    opsdb = db.OpsimDatabase(database)\n",
    "    \n",
    "    # Instantiate the metrics, stackers and slicer that we want to use. \n",
    "    # These are the TDC metrics, the season stacker, and the healpix slicer. \n",
    "    # Actually, since we'll just use the stackers in their default configuration, we don't need to \n",
    "    # explicitly instantiate the stackers -- MAF will handle that for us.  \n",
    "    # Note that the metric (TdcMetric) is actually a \"complex\" metric, as it calculates A, P, and f \n",
    "    # all in one go (thus re-using the cadence/season/campaign values which must also be calculated\n",
    "    # for each set of visits), and then has 'reduce' methods that separate each of these individual\n",
    "    # results into separate values. \n",
    "    metric = mafContrib.TdcMetric(metricName='TDC', seasonCol='season', expMJDCol='expMJD', nightCol='night')\n",
    "    slicer = slicers.HealpixSlicer(nside=64, lonCol='ditheredRA', latCol='ditheredDec')\n",
    "    \n",
    "    # Set the plotFuncs so that we only create the skymap and histogram for each metric result \n",
    "    # (we're not interested in the power spectrum). \n",
    "    plotFuncs = [plots.HealpixSkyMap, plots.HealpixHistogram]\n",
    "    slicer.plotFuncs = plotFuncs\n",
    "    \n",
    "    # Write the SQL constraint:\n",
    "    sql = 'night < %i' % (365.25*Nyears)\n",
    "    sqlstring = str(Nyears)+'years-'\n",
    "    if filters == 'ugrizy':\n",
    "        sql += ''\n",
    "        sqlstring += 'ugrizy'\n",
    "    elif filters == 'ri':\n",
    "        sql += ' and (filter=\"r\" or filter=\"i\")'\n",
    "        sqlstring += 'r+i-only'\n",
    "    else:\n",
    "        raise ValueError('Unrecognised filter set '+filters)\n",
    "\n",
    "    # Set the output directory name:\n",
    "    outDir = 'output_'+runName+'_'+sqlstring\n",
    "    \n",
    "    # Now bundle everything up:\n",
    "    tdcBundle = MetricBundle(metric=metric, slicer=slicer, sqlconstraint=sql, runName=runName)\n",
    "    resultsDb = db.ResultsDb(outDir=outDir)\n",
    "    bdict = {'tdc':tdcBundle}\n",
    "    bgroup = MetricBundleGroup(bdict, opsdb, outDir=outDir, resultsDb=resultsDb)\n",
    "\n",
    "    # And run the metrics!\n",
    "    bgroup.runAll()\n",
    "    \n",
    "    # Now to make the plots. \n",
    "    # Note that we now have more bundles in our bundle dictionary - these new bundles contain \n",
    "    # the results of the reduce functions - so, A/P/f separately:\n",
    "    #     bdict.keys() => ['tdc', 'TDC_Rate', 'TDC_Precision', 'TDC_Accuracy', 'TDC_Cadence', 'TDC_Campaign', 'TDC_Season']\n",
    "    # We want to set the plotDict for each of these separately, so that we can get each plot \n",
    "    # to look \"just right\", and then we'll make the plots.   \n",
    "    minVal = 0.01\n",
    "    maxVal = {'Accuracy':0.20, 'Precision':10.0, 'Rate':40, 'Cadence':14, 'Season':8.0, 'Campaign':11.0}\n",
    "    units = {'Accuracy':'%', 'Precision':'%', 'Rate':'%', 'Cadence':'days', 'Season':'months', 'Campaign':'years'}\n",
    "    for key in maxVal:\n",
    "        plotDict = {'xMin':minVal, 'xMax':maxVal[key], 'colorMin':minVal, 'colorMax':maxVal[key]}\n",
    "        plotDict['xlabel'] = 'TDC %s (%s)' % (key, units[key])\n",
    "        bdict['TDC_%s' % (key)].setPlotDict(plotDict)\n",
    "    \n",
    "    bgroup.plotAll(closefigs=False)\n",
    "    \n",
    "    # Now pull out metric values so that we can compute some useful summaries: \n",
    "    import numpy as np\n",
    "    x = tdcBundle.metricValues\n",
    "    index = np.where(x.mask == False)\n",
    "    f = np.array([each['rate'] for each in x[index]])\n",
    "    A = np.array([each['accuracy'] for each in x[index]])\n",
    "    P = np.array([each['precision'] for each in x[index]])\n",
    "    c = np.array([each['cadence'] for each in x[index]])\n",
    "    s = np.array([each['season'] for each in x[index]])\n",
    "    y = np.array([each['campaign'] for each in x[index]])\n",
    "\n",
    "    # Summaries:\n",
    "    results = dict()\n",
    "    results['runName'] = runName\n",
    "    results['filters'] = filters\n",
    "    results['Nyears'] = Nyears\n",
    "    \n",
    "    accuracy_threshold = 0.04 # 5 times better than threshold of 0.2% set by Hojjati & Linder (2014).\n",
    "    high_accuracy = np.where(A < accuracy_threshold)\n",
    "    results['high_accuracy_area_fraction'] = 100*(1.0*len(A[high_accuracy]))/(1.0*len(A))\n",
    "    print \"Fraction of total survey area providing high accuracy time delays = \",np.round(results['high_accuracy_area_fraction'],1),'%'\n",
    "\n",
    "    results['high_accuracy_cadence'] = np.median(c[high_accuracy])\n",
    "    print \"Median night-to-night cadence in high accuracy regions = \",np.round(results['high_accuracy_cadence'],1),'days'\n",
    "\n",
    "    results['high_accuracy_season'] = np.median(s[high_accuracy])\n",
    "    print \"Median season length in high accuracy regions = \",np.round(results['high_accuracy_season'],1),'months'\n",
    "\n",
    "    results['high_accuracy_campaign'] = np.median(y[high_accuracy])\n",
    "    print \"Median campaign length in high accuracy regions = \",int(results['high_accuracy_campaign']),'years'\n",
    "\n",
    "    Nside = 64\n",
    "    Npix = 12*Nside**2\n",
    "    Area_per_pixel = 4*np.pi / float(Npix) # steradians\n",
    "    Area_per_pixel *= (180.0/np.pi)*(180.0/np.pi) # square degrees\n",
    "    results['high_accuracy_area'] = len(A[high_accuracy])*Area_per_pixel\n",
    "    print \"Area of sky providing high accuracy time delays = \",int(results['high_accuracy_area']),\"sq deg\"\n",
    "\n",
    "    precision_per_lens = np.array([np.mean(P[high_accuracy]),4.0])\n",
    "    results['precision_per_lens'] = np.sqrt(np.sum(precision_per_lens*precision_per_lens))\n",
    "    print \"Mean precision per lens in high accuracy sample, including modeling error = \",np.round(results['precision_per_lens'],2),'%'\n",
    "\n",
    "    fraction = np.mean(f[high_accuracy])\n",
    "    results['N_lenses'] = int((results['high_accuracy_area']/18000.0) * (fraction/30.0) * 400)\n",
    "    print \"Number of lenses in high accuracy sample = \",results['N_lenses']\n",
    " \n",
    "    results['distance_precision'] = results['precision_per_lens'] / np.sqrt(results['N_lenses'])\n",
    "    print \"Maximum combined percentage distance precision (as in Coe & Moustakas 2009) = \",np.round(results['distance_precision'],2),'%'\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We'll save all our results in a single array, so that it can be used to make a `latex` table at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `minion_2016`: The Baseline Cadence - 10 years, ugrizy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.append(evaluate_opsim_run_for_time_delay_performance(runName='minion_1016', Nyears=10, filters='ugrizy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `minion_2016`: The Baseline Cadence - 5 years, ugrizy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.append(evaluate_opsim_run_for_time_delay_performance(runName='minion_1016', Nyears=5, filters='ugrizy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `minion_2016`: The Baseline Cadence - 10 years, r+i only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.append(evaluate_opsim_run_for_time_delay_performance(runName='minion_1016', Nyears=10, filters='ri'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `minion_2016`: The Baseline Cadence - 5 years, r+i only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results.append(evaluate_opsim_run_for_time_delay_performance(runName='minion_1016', Nyears=5, filters='ri'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `kraken_1043`: No Visit Pairs Required - 10 years, ugrizy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.append(evaluate_opsim_run_for_time_delay_performance(runName='kraken_1043', Nyears=10, filters='ugrizy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `kraken_1043`: No Visit Pairs Required - 5 years, ugrizy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.append(evaluate_opsim_run_for_time_delay_performance(runName='kraken_1043', Nyears=5, filters='ugrizy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `kraken_1043`: No Visit Pairs Required - 10 years, r+i only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.append(evaluate_opsim_run_for_time_delay_performance(runName='kraken_1043', Nyears=10, filters='ri'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `kraken_1043`: No Visit Pairs Required - 5 years, r+i only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.append(evaluate_opsim_run_for_time_delay_performance(runName='kraken_1043', Nyears=5, filters='ri'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting the Results\n",
    "\n",
    "For this we need to write a `latex` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_latex_table(results):\n",
    "    \"\"\"\n",
    "    Writes a latex table, with one row per test, presenting all the TDC metrics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results : list(dict)\n",
    "        List of results dictionaries, one per experiment.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The latex code is written to a simple .tex file for \\input into a document.\n",
    "    \n",
    "    Each element of the results list is a dictionary, like this:\n",
    "    {'high_accuracy_season': 6.9118266805479518, 'high_accuracy_area': 19004.12600851645, \n",
    "     'high_accuracy_area_fraction': 70.67103620474407, 'precision_per_lens': 5.0872446140504994, \n",
    "     'N_lenses': 468, 'Nyears': 10, 'runName': 'minion_1016', 'filters': 'ugrizy', \n",
    "     'high_accuracy_cadence': 4.5279775970305893, 'distance_precision': 0.23515796547162932, \n",
    "     'high_accuracy_campaign': 10.0}\n",
    "     \n",
    "    The interpretation of these numbers is as follows:\n",
    "    \n",
    "    Fraction of total survey area providing high accuracy time delays =  70.7 %\n",
    "    Median night-to-night cadence in high accuracy regions =  4.5 days\n",
    "    Median season length in high accuracy regions =  6.9 months\n",
    "    Median campaign length in high accuracy regions =  10 years\n",
    "    Area of sky providing high accuracy time delays =  19004 sq deg\n",
    "    Mean precision per lens in high accuracy sample, including modeling error =  5.09 %\n",
    "    Number of lenses in high accuracy sample =  468\n",
    "    Maximum combined percentage distance precision (as in Coe & Moustakas 2009) =  0.24 %\n",
    "\n",
    "    \"High accuracy\" means Accuracy metric > 0.04 \n",
    "    \n",
    "    Which element of results is which?\n",
    "    \n",
    "    for k in range(len(results)):\n",
    "       print k, results[k]['runName'], results[k]['filters'], results[k]['Nyears']\n",
    "\n",
    "    0 minion_1016 ugrizy 10\n",
    "    1 minion_1016 ugrizy 5\n",
    "    2 minion_1016 ri 10\n",
    "    3 minion_1016 ri 5\n",
    "    4 kraken_1043 ugrizy 10\n",
    "    5 kraken_1043 ugrizy 5\n",
    "    6 kraken_1043 ri 10\n",
    "    7 kraken_1043 ri 5\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open file object: \n",
    "    texfile = 'table_lenstimedelays.tex'\n",
    "    f = open(texfile, 'w')\n",
    "    \n",
    "    # Start latex:\n",
    "    tex = r'''\n",
    "\\begin{table*}\n",
    "\\begin{center}\n",
    "\\caption{Lens Time Delay Metric Analysis Results.}\n",
    "\\label{tab:lenstimedelays:results}\n",
    "\\footnotesize\n",
    "\\begin{tabularx}{\\linewidth}{ccccccccc}\n",
    "  \\hline\n",
    "  \\OpSim run                       % runName -> db\n",
    "   & Filters                       % filters\n",
    "    & Years                        % Nyears\n",
    "     & \\texttt{cadence}            % high_accuracy_cadence\n",
    "      & \\texttt{season}            % high_accuracy_season\n",
    "       & \\texttt{Area}             % high_accuracy_area\n",
    "        & \\texttt{dtPrecision}     % precision_per_lens\n",
    "         & \\texttt{Nlenses}        % N_lenses\n",
    "          & \\texttt{DPrecision} \\\\ % distance_precision\n",
    "  \\hline\\hline'''\n",
    "    f.write(tex)\n",
    "\n",
    "    # Now write the table rows:\n",
    "    for k in range(8):\n",
    "        x = results[k]\n",
    "        if x['runName'] == 'minion_1016':\n",
    "            x['db'] = '\\opsimdbref{db:baseCadence}'\n",
    "        elif x['runName'] == 'kraken_1043':\n",
    "            x['db'] = '\\opsimdbref{db:NoVisitPairs}'\n",
    "        else:\n",
    "            raise ValueError('Unrecognized runName: '+x['runName'])\n",
    "        tex = r'''\n",
    "  {db}\n",
    "   & ${filters}$\n",
    "    & ${Nyears:.0f}$\n",
    "     & ${high_accuracy_cadence:.1f}$\n",
    "      & ${high_accuracy_season:.1f}$\n",
    "       & ${high_accuracy_area:.0f}$\n",
    "        & ${precision_per_lens:.2f}$\n",
    "         & ${N_lenses:.0f}$\n",
    "          & ${distance_precision:.2f}$ \\\\'''.format(**x)\n",
    "        f.write(tex)\n",
    "        \n",
    "    # Now finish up the table:    \n",
    "    tex = r'''\n",
    "   \\hline\n",
    "\n",
    "\\multicolumn{9}{p{\\linewidth}}{\\scriptsize Notes: see the text for\n",
    "the definitions of each metric.}\n",
    "\\end{tabularx}\n",
    "\\normalsize\n",
    "\\medskip\\\\\n",
    "\\end{center}\n",
    "\\end{table*}'''\n",
    "    \n",
    "    # Write last part to file and close up:\n",
    "    f.write(tex)\n",
    "    f.close()\n",
    "    \n",
    "    # Report\n",
    "    print \"LaTeX table written to \"+texfile\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_latex_table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! cat table_lenstimedelays.tex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
