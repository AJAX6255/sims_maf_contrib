{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDEsAsciiMetric\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use TDEsAsciiMetric which calculate what fraction of an input TDE lightcurve would be detected. Paired with a spatial slicer, you can obtain the skymap or the observed light curve. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import healpy as hp\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "import lsst.sims.maf.db as db\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metric from mafContrib\n",
    "from mafContrib import TDEsAsciiMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated TDE light curve and the minimum requirement\n",
    "\n",
    "The TDEsAsciiMetric provides some prameters to meet the requirement of detection TDEs.\n",
    "\n",
    "- nObsTotal: Required total number of observations in each band.\n",
    "- nObsPrePeak: Required Number of observations before peak.\n",
    "- nObsNearPeak: Required number of observations in each band near peak.\n",
    "- nFiltersNearPeak: Required number of filters near peak.\n",
    "- nObsPostPeak: Required number of observations after peak.\n",
    "- nFiltersPostPeak: Required number of number of filters after peak.\n",
    "\n",
    "**Minimum requirement for detection TDEs** proposed by [Sjoert van Velzen](https://github.com/sjoertvv)\n",
    "\n",
    "- one detection before peak in any band to make sure we can roughly resolve the time/flux at peak,  set nObsPrePeak=1;\n",
    "- detections in three different bands within 10 days of peak to measure the color at peak, set nFiltersNearPeak=3, and nearPeakT=10;\n",
    "- detections at least two bands post peak within two weeks to measure the change of color, set nFiltersPostPeak=2, and postPeakT=14.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**set parameters according to input lightcurve template and minimum requirement**\n",
    "\n",
    "| parameters | value | meaning| \n",
    "| ---        | ---   |\n",
    "| epochStart | -22   |  Start epoch of input light curve |\n",
    "| peakEpoch  | 0     |  Peak epoch of input light curve  |\n",
    "| nearPeakT  | 10    |  Within 10 days around peakEpoch are considered as near peak |\n",
    "| postPeakT  | 14    |  Within two weeks after peakEpoch are considered as post peak |\n",
    "| nPhaseCheck| 1     |  Number of phases, 1 means only check the same phase as in ascii file |\n",
    "| nObsTotal  |{'u': 0, ...}| Number of total observations in each band |\n",
    "| nObsPrePeak| 1     | Number of observations before peak |\n",
    "|nObsNearPeak |{'u': 0, ...}| Number of observations in each band |\n",
    "|nFiltersNearPeak | 3 | Number of filters near peak |\n",
    "|nObsPostPeak | 0 | Number of observations after peak |\n",
    "|nFiltersPostPeak | 2 | Number of filters after peak |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lightcurve template is stored in an ascii file [TDEfaintfast_z0.1.dat](https://github.com/xiaolng/maf/blob/master/TDEfaintfast_z0.1.dat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# light curve file\n",
    "asciifile = 'TDEfaintfast_z0.1.dat'\n",
    "\n",
    "# query columns \n",
    "mjdCol = 'observationStartMJD'\n",
    "m5Col = 'fiveSigmaDepth'\n",
    "filterCol = 'filter'\n",
    "detectSNR={'u': 5, 'g': 5, 'r': 5, 'i': 5, 'z': 5, 'y': 5}\n",
    "\n",
    "# light curve parameters\n",
    "epochStart = -22\n",
    "peakEpoch = 0\n",
    "nearPeakT = 10\n",
    "postPeakT = 14 # two weeks\n",
    "nPhaseCheck = 1\n",
    "\n",
    "# condition parameters\n",
    "nObsTotal = {'u': 0, 'g': 0, 'r': 0, 'i': 0, 'z': 0, 'y': 0}\n",
    "nObsPrePeak = 1\n",
    "nObsNearPeak = {'u': 0, 'g': 0, 'r': 0, 'i': 0, 'z': 0, 'y': 0}\n",
    "nFiltersNearPeak = 3\n",
    "nObsPostPeak = 0 \n",
    "nFiltersPostPeak = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the light curve template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot light curve\n",
    "def plotlc(dataSlice, time_key='time', mag_key='mag', filter_key='filter', err_key = None,\n",
    "          peakEpoch=None, nearPeakT=None, postPeakT=None):\n",
    "    # Input: dataSlice, pandas DataFrame or numpy ndarray\n",
    "    \n",
    "    colors = {'u':'k', 'g':'b', 'r':'r', 'i':'m', 'z':'orange', 'y':'c'}\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for f in np.unique(dataSlice[filter_key]):\n",
    "        fmatch = dataSlice[filter_key]==f\n",
    "        time = dataSlice[time_key][fmatch]\n",
    "        mag = dataSlice[mag_key][fmatch]\n",
    "        \n",
    "        # draw a vertical line to denote pre/near/post peak\n",
    "        if peakEpoch!=None:\n",
    "            plt.axvline(x=peakEpoch, linestyle='-', linewidth=1)\n",
    "            plt.axvline(x=peakEpoch-nearPeakT/2, linestyle='--', linewidth=1)\n",
    "            plt.axvline(x=peakEpoch+nearPeakT/2, linestyle='--', linewidth=1)\n",
    "            plt.axvline(x=peakEpoch+nearPeakT/2+postPeakT, linestyle='--', linewidth=1)\n",
    "        \n",
    "        if err_key!=None:\n",
    "            mag_err = dataSlice[err_key][fmatch]\n",
    "            plt.errorbar(time, mag, yerr=mag_err, color=colors[f], fmt='.', label=f)\n",
    "        else:\n",
    "            plt.scatter(time, mag, color=colors[f], marker='*', label=f)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('days')\n",
    "    plt.ylabel('mag')\n",
    "    plt.ylim(plt.ylim()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch [days] \\n An example of an input lightcurve template. \\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asciifile = '../../data/tde/TDEfaintfast_z0.1.dat'\n",
    "\n",
    "lcv_template = np.genfromtxt(asciifile, dtype=[('ph', 'f8'), ('mag', 'f8'), ('flt', 'S1')])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['ph'] = lcv_template['ph']\n",
    "df['mag'] = lcv_template['mag']\n",
    "df['flt'] = lcv_template['flt'].astype(str)\n",
    "\n",
    "plotlc(df, time_key='ph', mag_key='mag', filter_key='flt', \n",
    "       peakEpoch=peakEpoch, nearPeakT=nearPeakT, postPeakT=postPeakT)\n",
    "\n",
    "plt.xlabel('epoch [days] \\n An example of an input lightcurve template. \\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opsim database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to opsim database and get the proposalId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal table available - no proposalIds have been assigned.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({}, {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to opsim database\n",
    "opsdb_baseline = db.OpsimDatabase('baseline_v1.3_10yrs.db')\n",
    "opsdb_baseline.fetchPropInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory\n",
    "outDir = 'outdir'\n",
    "resultsDb = db.ResultsDb(outDir=outDir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get skymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initializing metric\n",
      "Healpix slicer using NSIDE=16, approximate resolution 219.871130 arcminutes\n",
      "Querying database SummaryAllProps with constraint night<730 for columns ['fieldRA', 'observationStartMJD', 'fieldDec', 'filter', 'fiveSigmaDepth']\n",
      "Found 420180 visits\n",
      "Running:  ['transmetricSky']\n",
      "Completed metric generation.\n",
      "Running reduce methods.\n",
      "Running summary statistics.\n",
      "Completed.\n",
      "Plotting figures with \"night<730\" constraint now.\n",
      "monopole: 0.0419786  dipole: lon: -9.38153, lat: -67.2205, amp: 0.0366427\n",
      "Plotting complete.\n"
     ]
    }
   ],
   "source": [
    "# get skymap by set dataout=False and use HealpixSlicer()\n",
    "transmetric = TDEsAsciiMetric(asciifile=None, mjdCol=mjdCol, m5Col=m5Col, filterCol=filterCol, \n",
    "                              detectSNR=detectSNR, epochStart=epochStart, peakEpoch=peakEpoch, \n",
    "                              nearPeakT=nearPeakT, postPeakT=postPeakT, nPhaseCheck=nPhaseCheck,\n",
    "                              nObsTotal= nObsTotal, nObsPrePeak=nObsPrePeak, \n",
    "                              nObsNearPeak=nObsNearPeak, nFiltersNearPeak=nFiltersNearPeak, \n",
    "                              nObsPostPeak=nObsPostPeak, nFiltersPostPeak=nFiltersPostPeak,\n",
    "                              dataout=False)\n",
    "\n",
    "slicer = slicers.HealpixSlicer(nside=16) \n",
    "sqlconstraint = 'night<730'\n",
    "\n",
    "transmetricSky = metricBundles.MetricBundle(transmetric,slicer,sqlconstraint)\n",
    "\n",
    "group = metricBundles.MetricBundleGroup({'transmetricSky':transmetricSky}, opsdb_baseline, outDir=outDir, resultsDb=resultsDb)\n",
    "group.runAll()\n",
    "group.plotAll(closefigs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a pd.DataFrame and save the skymap info for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './opsdb/baseline2018_skymap.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e91f82b51bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metricValues'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./opsdb/baseline2018_skymap.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lsst/python/miniconda3-4.5.12/envs/lsst-scipipe-1172c30/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 3020\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lsst/python/miniconda3-4.5.12/envs/lsst-scipipe-1172c30/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lsst/python/miniconda3-4.5.12/envs/lsst-scipipe-1172c30/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './opsdb/baseline2018_skymap.csv'"
     ]
    }
   ],
   "source": [
    "baseline2018_skymap = transmetricSky.metricValues\n",
    "\n",
    "# create a dataframe and save to csv file\n",
    "df = pd.DataFrame(baseline2018_skymap)\n",
    "df['ipix'] = df.index \n",
    "df['ra'] = hp.pix2ang(ipix=df['ipix'], nside=16, lonlat=True)[0]\n",
    "df['dec'] = hp.pix2ang(ipix=df['ipix'], nside=16, lonlat=True)[1]\n",
    "df['metricValues'] = df[0]\n",
    "del df[0]\n",
    "df.to_csv('./opsdb/baseline2018_skymap.csv', index=False, na_rep='NaN')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all metric values \n",
    "np.unique(baseline2018_skymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the all ipixes for a metric value\n",
    "np.where(baseline2018_skymap==0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the (ra,dec) for a ipix\n",
    "hp.pix2ang(ipix=1549, nside=16, lonlat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get light curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## get light curve by set dataout=True and use UserPointSlicer()\n",
    "transmetric = TDEsAsciiMetric(asciifile=asciifile, mjdCol=mjdCol, m5Col=m5Col, filterCol=filterCol, detectSNR=detectSNR,\n",
    "                 epochStart=epochStart, peakEpoch=peakEpoch, nearPeakT=nearPeakT, nPhaseCheck=nPhaseCheck,\n",
    "                 nObsTotal= nObsTotal,nObsPrePeak=nObsPrePeak, \n",
    "                 nObsNearPeak=nObsNearPeak, nFiltersNearPeak=nFiltersNearPeak, \n",
    "                 nObsPostPeak=nObsPostPeak, nFiltersPostPeak=nFiltersPostPeak,\n",
    "                 dataout=True)\n",
    "# ra,dec of ipix \n",
    "ra = np.array([255.9375])\n",
    "dec = np.array([0.0])\n",
    "slicer = slicers.UserPointsSlicer(ra, dec)\n",
    "\n",
    "sqlconstraint = 'night<730 and proposalId=3'\n",
    "transmetricSky = metricBundles.MetricBundle(transmetric,slicer,sqlconstraint)\n",
    "\n",
    "group = metricBundles.MetricBundleGroup({'transmetricSky':transmetricSky}, opsdb_baseline, outDir=outDir, resultsDb=resultsDb)\n",
    "group.runAll()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output metricValues is a list of dictionaries for each phase(tshift). Each dictionary contains arrays of \n",
    "\n",
    "|  variable   |  meaning   |\n",
    "| --- | --- |\n",
    "| 'tshift' | the phase shift of the light curve|\n",
    "| 'expMJD' | the time column |\n",
    "| 'm5'     | the fiveSigmaDepth |\n",
    "|'filters' | filters |\n",
    "| 'lcNumber'| number of light curve|\n",
    "|'lcEpoch' | epoch of the light curve |\n",
    "| 'prePeakCheck' | equals True for prePeak observations |\n",
    "| 'nearPeakCheck'| equals True for nearPeak observations|\n",
    "| 'postPeakCheck'| equals True for postPeak observations|\n",
    "| 'lcMags'| magnitudes of the light curve|\n",
    "| 'lcSNR' | signal to noise ratio|\n",
    "| 'lcMagsStd'| standard deviation of magnitudes|\n",
    "| 'lcAboveThresh'| equals True if for detected magnitudes|\n",
    "| 'detected' |equals True if this light curve was detected|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save file and plot light curve\n",
    "output_dict_list = transmetricSky.metricValues.data[0]\n",
    "df = pd.DataFrame(output_dict_list[0])\n",
    "\n",
    "df.to_csv('./opsdb/baseline2018_lc.csv', index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output light curve can be plotted use the same function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load from csv\n",
    "# df = pd.read_csv('./opsdb/baseline2018_lc.csv')\n",
    "\n",
    "# plot all light curve\n",
    "# plotlc(df[ (df['lcAboveThresh'])], time_key='expMJD', mag_key='lcMags', filter_key='filters', err_key='lcMagsStd')\n",
    "\n",
    "# plot a specific light curve\n",
    "plotlc(df[ (df['lcAboveThresh']) & (df['lcNumber']==0)], time_key='lcEpoch', mag_key='lcMags', filter_key='filters', err_key='lcMagsStd', \n",
    "       peakEpoch=peakEpoch, nearPeakT=nearPeakT, postPeakT=postPeakT)\n",
    "\n",
    "plt.xlabel('epoch [days] \\n An example of detected light curve from baseline2018.\\n' + \n",
    "           'It meets the minimum requirements: one detection before peak,\\n three filters near peak, and two filters post peak within two weeks ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other opsim databases can be explored by following the same procedure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
