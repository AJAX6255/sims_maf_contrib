{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook looks at detection of a simple SN Ia model in various survey strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import healpy as hp\n",
    "\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "import lsst.sims.maf.db as db\n",
    "import mafContrib as mafContrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at year=9 at most of the galactic plane etc. work is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple SN Ia, z=0.5, stretch=1, colour=0 event from SiFTO. AB mAGS. These peak mags are in DES filters.\n",
    "\n",
    "At z=0.5, the rise is $18d*(1+z)=27$ and we want to follow the event for about 20 days post max in the rest-frame. But we will never detect in the first few days so we just say we care about the 10 days prior to peak ie a rise of 15d observer frame.\n",
    "\n",
    "We mock-up the rise as 2 mags over peak time, and the fall as 1.4 mags over 30 observer days in r at z=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "size of tuple must match number of fields.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e5b5dc6954fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                          \u001b[0;34m'i'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iai.nugent.lc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                          \u001b[0;34m'z'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iaz.nugent.lc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                                          'y': 'Iay.nugent.lc'})\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# Generate and plot the (daily) lightcurve.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransDuration\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lynnej/lsstRepos/sims_maf_contrib/mafContrib/transientAsciiMetric.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, metricName, mjdCol, m5Col, filterCol, surveyDuration, surveyStart, detectM5Plus, detectfactor, maxdiscT, nPreT, nPerLC, nFilters, nPhaseCheck, peakOffset, asciifile, dataout, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masciifile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masciifile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Read lightcurve here, as it doesn't change.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minlcv_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_lightCurve_SV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_lightCurve_SV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lynnej/lsstRepos/sims_maf_contrib/mafContrib/transientAsciiMetric.py\u001b[0m in \u001b[0;36mread_lightCurve_SV\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masciifile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ph'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'mag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'flt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'S1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransDuration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lynnej/anaconda/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows)\u001b[0m\n\u001b[1;32m   1832\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1834\u001b[0;31m                 \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype_flat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m             \u001b[0;31m# Now, process the rowmasks the same way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: size of tuple must match number of fields."
     ]
    }
   ],
   "source": [
    "reload(mafContrib)\n",
    "# Trying to make a type Ia-like \n",
    "peaks = {'uPeak': 20.9, \n",
    "         'gPeak': 18.6, \n",
    "         'rPeak': 18.6, \n",
    "         'iPeak': 18.7, \n",
    "         'zPeak': 18.7,\n",
    "         'yPeak': 18.8}\n",
    "\n",
    "colors = ['b', 'g', 'r', 'purple', 'y', 'magenta', 'k']\n",
    "\n",
    "filterNames = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "peakTime = 15\n",
    "transDuration = 100 # Days\n",
    "transMetric = mafContrib.TransientAsciiMetric(surveyDuration=1, \n",
    "                                              peakOffset=peaks,\n",
    "                                              detectfactor={'u':1,'g':1,'r':1,'i':1,'z':1,'y':1},\n",
    "                                              nFilters=2, nPreT=2, nPerLC=1,\n",
    "                                              asciifile={'u': 'Iau.nugent.lc',\n",
    "                                                         'g': 'Iag.nugent.lc',\n",
    "                                                         'r': 'Iar.nugent.lc',\n",
    "                                                         'i': 'Iai.nugent.lc',\n",
    "                                                         'z': 'Iaz.nugent.lc',\n",
    "                                                         'y': 'Iay.nugent.lc'})\n",
    "# Generate and plot the (daily) lightcurve.\n",
    "times = np.arange(0., transDuration*2, 1)\n",
    "for filterName, color in zip(filterNames, colors):\n",
    "    filters = np.array([filterName]*times.size)\n",
    "    lc = transMetric.lightCurve_SV(times, filters)\n",
    "    plt.plot(times,lc, color, label=filterName)\n",
    "plt.xlabel('time (days)')\n",
    "plt.ylabel('mags')\n",
    "plt.ylim([35,18])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What fraction are detected at least once in any filter?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pick a slicer\n",
    "slicer = slicers.HealpixSlicer(nside=64)\n",
    "\n",
    "summaryMetrics = [metrics.MedianMetric(), metrics.PercentileMetric()]\n",
    "# Configure some metrics\n",
    "metricList = []\n",
    "# What fraction are detected at least once?\n",
    "metricList.append(transMetric)\n",
    "#metricList.append(transMetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the database and query\n",
    "runName = 'enigma_1189'#'enigma_1189' \n",
    "#runName = 'ops1_1160'#'enigma_1189' \n",
    "sqlconstraint = 'night between %f and %f and ((filter = \"r\" or filter = \"g\" ) OR (filter = \"r\" or filter = \"u\" ) or (filter = \"i\" or filter = \"g\" ) or (filter = \"i\" or filter = \"u\" ))'% ((365.25*year,365.25*(year+0.03)))\n",
    "bDict={}\n",
    "for i,metric in enumerate(metricList):\n",
    "    bDict[i] = metricBundles.MetricBundle(metric, slicer, sqlconstraint, \n",
    "                                          runName=runName, summaryMetrics=summaryMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE - change your path and/or opsim database here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opsdb = db.OpsimDatabase('sqlite:///' + runName + '_sqlite.db')\n",
    "outDir = 'Transients'\n",
    "resultsDb = db.ResultsDb(outDir=outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgroup = metricBundles.MetricBundleGroup(bDict, opsdb, outDir=outDir, resultsDb=resultsDb, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bgroup.runAll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgroup.plotAll(closefigs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgroup.writeAll()\n",
    "print bgroup.outDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in bDict:\n",
    "    bDict[key].computeSummaryStats(resultsDb=resultsDb)\n",
    "    print bDict[key].metric.name, bDict[key].summaryValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What fraction are detected at least 6 times in one of g r i z, 3 in first half, 3 in second half\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transMetric = metrics.TransientMetric(riseSlope= -2./peakTime, declineSlope=1.4/30., \n",
    "                                      transDuration=transDuration, peakTime=peakTime, surveyDuration=1, \n",
    "                                      nFilters=3, nPrePeak=3, nPerLC=2, **peaks)\n",
    "\n",
    "sqlconstraint = '(filter=\"r\" or filter=\"g\" or filter=\"i\" or filter=\"z\") and night between %f and %f' % (365.25*year,365.25*(year+0.1))\n",
    "transBundle = metricBundles.MetricBundle(transMetric, slicer, sqlconstraint, \n",
    "                                          runName=runName, summaryMetrics=summaryMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "bgroup = metricBundles.MetricBundleGroup({0:transBundle}, opsdb, outDir=outDir, resultsDb=resultsDb)\n",
    "bgroup.runAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgroup.plotAll(closefigs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Keywords that we need to add:\n",
    "\n",
    "* Total number of points\n",
    "* Gap time to demand between points in the same filter to count them as independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What fraction are detected at least 9 times in one of g r i z, 3 in each third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transMetric = metrics.TransientMetric(riseSlope= -2./peakTime, declineSlope=1.4/30., \n",
    "                                      transDuration=transDuration, peakTime=peakTime, surveyDuration=1, \n",
    "                                      nFilters=3, nPrePeak=3, nPerLC=3, **peaks)\n",
    "\n",
    "sqlconstraint = '(filter=\"r\" or filter=\"g\" or filter=\"i\" or filter=\"z\") and night between %f and %f'% (365.25*year,365.25*(year+1))\n",
    "transBundle = metricBundles.MetricBundle(transMetric, slicer, sqlconstraint, \n",
    "                                          runName=runName, summaryMetrics=summaryMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgroup = metricBundles.MetricBundleGroup({0:transBundle}, opsdb, outDir=outDir, resultsDb=resultsDb)\n",
    "bgroup.runAll()\n",
    "bgroup.plotAll(closefigs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExtractLC(metrics.TransientMetric):\n",
    "    \"\"\"\n",
    "    Be identical to the Transient Metric, but just save the light curves that\n",
    "    meet the criteria.\n",
    "    \"\"\"\n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "\n",
    "        # Total number of transients that could go off back-to-back\n",
    "        nTransMax = np.floor(self.surveyDuration/(self.transDuration/365.25))\n",
    "        tshifts = np.arange(self.nPhaseCheck)*self.transDuration/float(self.nPhaseCheck)\n",
    "        nDetected = 0\n",
    "        nTransMax = 0\n",
    "        for tshift in tshifts:\n",
    "            # Compute the total number of back-to-back transients are possible to detect\n",
    "            # given the survey duration and the transient duration.\n",
    "            nTransMax += np.floor(self.surveyDuration/(self.transDuration/365.25))\n",
    "            if tshift != 0:\n",
    "                nTransMax -= 1\n",
    "            if self.surveyStart is None:\n",
    "                surveyStart = dataSlice[self.mjdCol].min()\n",
    "            time = (dataSlice[self.mjdCol] - surveyStart + tshift) % self.transDuration\n",
    "\n",
    "            # Which lightcurve does each point belong to\n",
    "            lcNumber = np.floor((dataSlice[self.mjdCol]-surveyStart)/self.transDuration)\n",
    "\n",
    "            lcMags = self.lightCurve(time, dataSlice[self.filterCol])\n",
    "\n",
    "            # How many criteria needs to be passed\n",
    "            detectThresh = 0\n",
    "\n",
    "            # Flag points that are above the SNR limit\n",
    "            detected = np.zeros(dataSlice.size, dtype=int)\n",
    "            detected[np.where(lcMags < dataSlice[self.m5Col] + self.detectM5Plus)] += 1\n",
    "            detectThresh += 1\n",
    "\n",
    "            # If we demand points on the rise\n",
    "            if self.nPrePeak > 0:\n",
    "                detectThresh += 1\n",
    "                ord = np.argsort(dataSlice[self.mjdCol])\n",
    "                dataSlice = dataSlice[ord]\n",
    "                detected = detected[ord]\n",
    "                lcNumber = lcNumber[ord]\n",
    "                time = time[ord]\n",
    "                ulcNumber = np.unique(lcNumber)\n",
    "                left = np.searchsorted(lcNumber, ulcNumber)\n",
    "                right = np.searchsorted(lcNumber, ulcNumber, side='right')\n",
    "                # Note here I'm using np.searchsorted to basically do a 'group by'\n",
    "                # might be clearer to use scipy.ndimage.measurements.find_objects or pandas, but\n",
    "                # this numpy function is known for being efficient.\n",
    "                for le,ri in zip(left,right):\n",
    "                    # Number of points where there are a detection\n",
    "                    good = np.where(time[le:ri] < self.peakTime)\n",
    "                    nd = np.sum(detected[le:ri][good])\n",
    "                    if nd >= self.nPrePeak:\n",
    "                        detected[le:ri] += 1\n",
    "\n",
    "            # Check if we need multiple points per light curve or multiple filters\n",
    "            if (self.nPerLC > 1) | (self.nFilters > 1) :\n",
    "                # make sure things are sorted by time\n",
    "                ord = np.argsort(dataSlice[self.mjdCol])\n",
    "                dataSlice = dataSlice[ord]\n",
    "                detected = detected[ord]\n",
    "                lcNumber = lcNumber[ord]\n",
    "                ulcNumber = np.unique(lcNumber)\n",
    "                left = np.searchsorted(lcNumber, ulcNumber)\n",
    "                right = np.searchsorted(lcNumber, ulcNumber, side='right')\n",
    "                detectThresh += self.nFilters\n",
    "\n",
    "                for le,ri in zip(left,right):\n",
    "                    points = np.where(detected[le:ri] > 0)\n",
    "                    ufilters = np.unique(dataSlice[self.filterCol][le:ri][points])\n",
    "                    phaseSections = np.floor(time[le:ri][points]/self.transDuration * self.nPerLC)\n",
    "                    for filtName in ufilters:\n",
    "                        good = np.where(dataSlice[self.filterCol][le:ri][points] == filtName)\n",
    "                        if np.size(np.unique(phaseSections[good])) >= self.nPerLC:\n",
    "                            detected[le:ri] += 1\n",
    "\n",
    "\n",
    "        return {'lcNumber':lcNumber, 'lcMag':lcMag, 'detected':detected,\n",
    "                'time':time, 'detectThresh':detectThresh, 'filter':dataSlice[self.filterCol]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lcM = ExtractLC(riseSlope= -2.3/peakTime, declineSlope=1.6/30., \n",
    "                                      transDuration=transDuration, peakTime=peakTime, surveyDuration=1, \n",
    "                                      nFilters=3, nPrePeak=3, nPerLC=2, **peaks)\n",
    "\n",
    "sqlconstraint = '(filter=\"r\" or filter=\"g\" or filter=\"i\" or filter=\"z\") and night between %f and %f and fieldRA < ? and fieldDec > ? ' % (365.25*year,365.25*(year+1))\n",
    "transBundle = metricBundles.MetricBundle(transMetric, slicer, sqlconstraint, \n",
    "                                          runName=runName, summaryMetrics=summaryMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgroup = metricBundles.MetricBundleGroup({0:transBundle}, opsdb, outDir=outDir, resultsDb=resultsDb)\n",
    "bgroup.runAll()\n",
    "bgroup.plotAll(closefigs=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
